# PBIP GenAI Dashboard

A Generative AI pipeline that automates the creation of Power BI dashboards. It takes natural language user queries, interprets them using an LLM, and generates a fully functional Power BI Report (`.pbip` format) with relevant visuals, correct semantic bindings, and auto-configured slicers.

## Features

- **Natural Language to Report**: Converts "Show me sales trends" into a physical Power BI report.
- **Smart Visual Planning**: Uses an LLM Agent to decide the best visuals (KPI Cards, Line Charts, Bar Charts, etc.).
- **Semantic Awareness**: Indexes your specific Power BI Semantic Model (`.tmdl`) to understand your data and terminology.
- **Auto-Synonym Generation**: Automatically expands terms (e.g., "Revenue" -> `total_price`) using an AI agent.
- **Smart Injection**: Automatically detects date-based visuals and injects a **Date Slicer** connected to the correct hidden `LocalDateTable`.
- **Token Optimization**: Separated "Build" and "Run" phases to minimize LLM impact and cost.

## Project Structure

```
├── agents/                 # AI Agents (Planner, Synonym Generator, etc.)
├── backend/                # PBIP Writer (JSON generation)
├── compiler/               # Semantic Binder & Resolver
├── config/                 # Configuration settings
├── core/                   # Pydantic Models (Internal Representation)
├── discovery/              # TMDL Parser & Indexer
├── llm/                    # LLM Clients & Token Tracker
├── metadata/               # Cached metadata (Generated by build script)
├── PowerBI/                # Your source Power BI Project folder
├── tests/                  # Unit tests and scripts
├── build_metadata.py       # [Build Phase] Generates index & synonyms
├── run_cached_pipeline.py  # [Run Phase] Executes the pipeline fast
└── pipeline.py             # (Legacy) One-shot pipeline
```

## Setup & Installation

1.  **Install Python 3.10+**
2.  **Install Dependencies**:
    ```bash
    pip install -r requirements.txt
    ```
3.  **Environment Variables**:
    Create a `.env` file in the root directory with your API keys:
    ```ini
    GROQ_PLANNER_KEY=gsk_...
    GROQ_DASHBOARD_KEY=gsk_...
    GROQ_SYNONYM_KEY=gsk_...
    ```

## Usage

### Phase 1: Build Metadata (One-Time)
Run this script whenever your Power BI Semantic Model (TMDL) changes, or if you want to refresh the synonyms.
```bash
python build_metadata.py
```
*This extracts the schema, identifies hidden tables, and generates linguistic synonyms using the LLM. The output is saved to `metadata/`.*

### Phase 2: Generate Reports (Regular Usage)
Run the cached pipeline to generate reports from your queries instantly.
```bash
python run_cached_pipeline.py
```
*Edit the `query` variable in `run_cached_pipeline.py` to change your request.*

## How It Works

1.  **Discovery**: Parses TMDL files to understand Tables, Columns, Measures, and Hidden Date Tables.
2.  **Planning**: An LLM Architect plans the dashboard layout and visual types based on your query.
3.  **Binding**: The system fuzzily maps abstract concepts (e.g., "Sales") to physical columns (e.g., `orders_rows.total_price`).
4.  **Refinement**: 
    - Auto-injects KPI cards if performance is requested.
    - Auto-injects Date Slicers if time-series data is detected.
5.  **Generation**: Writes standard Power BI JSON files (`visual.json`) into the Report folder.

## Requirements

- Power BI Desktop (with PBIP format enabled)
- A valid Semantic Model folder (TMDL format) at the configured path.